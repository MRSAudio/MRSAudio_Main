import json
import os
import librosa
import soundfile as sf
from multiprocessing import Pool
from tqdm import tqdm
from collections import OrderedDict

json_base_dir = "./3D-Speaker/output"
# json_base_dir = "/home2/zhangyu/gwx/asr_fix"
wav_base_dir = "./Spatial/play"

def merge_segments(segments):
    """åˆå¹¶è¿ç»­çš„åŒä¸€è¯´è¯äººç‰‡æ®µï¼ˆæ”¯æŒä»»æ„æ•°é‡è¿ç»­ç‰‡æ®µï¼‰"""
    if not segments:
        return []

    # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    sorted_segments = sorted(segments, key=lambda x: x["start"])
    merged = []
    
    i = 0
    while i < len(sorted_segments):
        current = {
            "start": sorted_segments[i]["start"],
            "stop": sorted_segments[i]["stop"],
            "speaker": sorted_segments[i]["speaker"],
            "original_keys": [sorted_segments[i]["key"]]
        }
        
        # åˆå¹¶åç»­å¯åˆå¹¶çš„ç‰‡æ®µ
        j = i + 1
        while j < len(sorted_segments):
            next_seg = sorted_segments[j]
            # åˆå¹¶æ¡ä»¶ï¼šåŒä¸€è¯´è¯äººä¸”æ—¶é—´è¿ç»­/é‡å 
            if (next_seg["speaker"] == current["speaker"] 
                and next_seg["start"] <= current["stop"] + 0.01):
                current["stop"] = max(current["stop"], next_seg["stop"])
                current["original_keys"].append(next_seg["key"])
                j += 1
            else:
                break
        
        merged.append(current)
        i = j  # ç›´æ¥è·³åˆ°æœªå¤„ç†çš„ä½ç½®
    
    return merged

def process_single_file(json_path):
    """å¤„ç†å•ä¸ªJSONæ–‡ä»¶"""
    results = {
        'total_clips': 0,
        'merged_clips': 0,
        'success': 0,
        'skipped': 0,
        'errors': [],
        'file_error': None
    }
    
    try:
        # åŸºç¡€ä¿¡æ¯è§£æ
        base_name = os.path.basename(json_path)
        session_id = base_name.replace("_ç¼©æ··_cut_new.json", "")
        wav_dir = os.path.join(wav_base_dir, session_id)
        
        # åŸå§‹éŸ³é¢‘è·¯å¾„
        original_wav_path = os.path.join(
            wav_base_dir, 
            os.path.basename(wav_dir),
            os.path.basename(wav_dir) + "_ç¼©æ··_cut.wav" 
        )
        if not os.path.exists(original_wav_path):
            raise FileNotFoundError(f"åŸå§‹éŸ³é¢‘ä¸å­˜åœ¨: {original_wav_path}")

        # åŠ è½½éŸ³é¢‘
        with sf.SoundFile(original_wav_path) as f:
            original_subtype = f.subtype
        y, sr = librosa.load(original_wav_path, sr=None, mono=False)
        if y.ndim == 1:
            raise ValueError("å•å£°é“éŸ³é¢‘ä¸ç¬¦åˆè¦æ±‚")
        y = y.T  # (samples, channels)

        # åŠ è½½å¹¶å¤„ç†åˆ‡å‰²é…ç½®
        with open(json_path, 'r') as f:
            raw_data = json.load(f, object_pairs_hook=OrderedDict)
        
        # å‡†å¤‡åˆå¹¶æ•°æ®ï¼ˆä¿ç•™åŸå§‹keyï¼‰
        segments = []
        for key, value in raw_data.items():
            segments.append({
                "key": key,
                "start": value["start"],
                "stop": value["stop"],
                "speaker": value["speaker"],
                "text": value["text"]
            })
        
        # åˆå¹¶ç‰‡æ®µ
        merged_segments = merge_segments(segments)
        results['total_clips'] = len(segments)
        results['merged_clips'] = len(merged_segments)

        # ç”Ÿæˆæ–°é…ç½®
        new_config = OrderedDict()
        output_dir = os.path.join(wav_dir, "split_spker")
        os.makedirs(output_dir, exist_ok=True)

        for seg in merged_segments:
            # ç”Ÿæˆæ–°é”®åï¼ˆä¿ç•™åŸå§‹æ—¶é—´ç²¾åº¦ï¼‰
            new_key = f"{session_id}_ç¼©æ··_cut_{seg['start']:.3f}_{seg['stop']:.3f}_{seg['speaker']}"
            
            # æ„å»ºè¾“å‡ºè·¯å¾„
            output_wav_path = os.path.join(
                output_dir,
                f"{new_key}.wav"
            )
            
            # è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶
            if os.path.exists(output_wav_path):
                results['skipped'] += 1
                new_config[new_key] = {
                    "start": seg['start'],
                    "stop": seg['stop'],
                    "speaker": seg['speaker'],
                    # "text": seg['text'] 
                }
                continue

            try:
                # åˆ‡å‰²éŸ³é¢‘
                start_sample = int(seg["start"] * sr)
                end_sample = int(seg["stop"] * sr)
                y_cut = y[start_sample:end_sample]
                
                # ä¿å­˜æ–‡ä»¶
                sf.write(output_wav_path, y_cut, sr, subtype=original_subtype)
                new_config[new_key] = {
                    "start": seg['start'],
                    "stop": seg['stop'],
                    "speaker": seg['speaker'],
                    # "text": seg['text'] 
                }
                results['success'] += 1
            except Exception as e:
                error_msg = f"{new_key} (åŸå§‹keys: {seg['original_keys']}): {str(e)}"
                results['errors'].append(error_msg)

        # ä¿å­˜æ–°é…ç½®æ–‡ä»¶ï¼ˆè¦†ç›–åŸæ–‡ä»¶ï¼‰
        new_json_path = os.path.join(wav_dir, base_name)
        # print(f"ä¿å­˜æ–°é…ç½®åˆ°: {new_json_path}")
        # print(f"æ–°é…ç½®: {new_config}")
        with open(new_json_path, 'w') as f:
            json.dump(new_config, f, indent=4, ensure_ascii=False)

    except Exception as e:
        results['file_error'] = f"{json_path}: {str(e)}"
    
    return results

def count_total_clips(json_files):
    """ç»Ÿè®¡åŸå§‹ç‰‡æ®µæ€»æ•°"""
    total = 0
    for path in json_files:
        try:
            with open(path, 'r') as f:
                total += len(json.load(f))
        except:
            continue
    return total

def main():
    # æ”¶é›†JSONæ–‡ä»¶
    json_files = [
        os.path.join(json_base_dir, f)
        for f in os.listdir(json_base_dir)
        if f.endswith("_ç¼©æ··_cut_new.json")
    ]
    
    # é¢„ç»Ÿè®¡
    print("æ­£åœ¨æ‰«æä»»åŠ¡...")
    total_original = count_total_clips(json_files)
    print(f"å‘ç° {len(json_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {total_original} ä¸ªåŸå§‹ç‰‡æ®µ")

    # åˆå§‹åŒ–ç»Ÿè®¡
    stats = {
        'total_original': total_original,
        'total_merged': 0,
        'success': 0,
        'skipped': 0,
        'errors': [],
        'file_errors': []
    }

    # è¿›åº¦æ¡
    pbar = tqdm(total=len(json_files), desc="ğŸ”„ å¤„ç†æ–‡ä»¶ä¸­")

    # å¹¶è¡Œå¤„ç†
    with Pool(32) as pool:
        for result in pool.imap_unordered(process_single_file, json_files):
            # æ›´æ–°ç»Ÿè®¡
            stats['total_merged'] += result['merged_clips']
            stats['success'] += result['success']
            stats['skipped'] += result['skipped']
            stats['errors'].extend(result['errors'])
            if result['file_error']:
                stats['file_errors'].append(result['file_error'])
            
            # æ›´æ–°è¿›åº¦
            pbar.update(1)
            pbar.set_postfix({
                'åˆå¹¶ç‡': f"{1 - stats['total_merged']/stats['total_original']:.1%}",
                'æˆåŠŸç‡': f"{stats['success']/stats['total_merged']:.1%}" if stats['total_merged'] else '0%'
            })

    pbar.close()

    # è¾“å‡ºæŠ¥å‘Š
    print("\nå¤„ç†æŠ¥å‘Š:")
    print(f"åŸå§‹ç‰‡æ®µæ€»æ•°: {stats['total_original']}")
    print(f"åˆå¹¶åç‰‡æ®µæ•°: {stats['total_merged']} (å‡å°‘ {stats['total_original']-stats['total_merged']})")
    print(f"æˆåŠŸç”Ÿæˆ: {stats['success']}")
    print(f"è·³è¿‡æ–‡ä»¶: {stats['skipped']}")
    print(f"å¤±è´¥ç‰‡æ®µ: {len(stats['errors'])}")
    print(f"å¤±è´¥æ–‡ä»¶: {len(stats['file_errors'])}")

    # é”™è¯¯æ—¥å¿—
    if stats['errors'] or stats['file_errors']:
        for err in stats['file_errors'][:10]:
            print(f"æ–‡ä»¶é”™è¯¯: {err}")
        for err in stats['errors'][:10]:
            print(f"ç‰‡æ®µé”™è¯¯: {err}")
            
if __name__ == "__main__":
    main()